{"documentCount":34,"nextId":35,"documentIds":{"1":"lib\\scripts\\graph-wasm.wasm","2":"lib\\fonts\\94f2f163d4b698242fef.otf","3":"lib\\fonts\\72505e6a122c6acd5471.woff2","4":"lib\\fonts\\2d5198822ab091ce4305.woff2","5":"lib\\fonts\\c8ba52b05a9ef10f4758.woff2","6":"lib\\fonts\\cb10ffd7684cd9836a05.woff2","7":"lib\\fonts\\b5f0f109bc88052d4000.woff2","8":"lib\\fonts\\cbe0ae49c52c920fd563.woff2","9":"lib\\fonts\\535a6cf662596b3bd6a6.woff2","10":"lib\\fonts\\70cc7ff27245e82ad414.ttf","11":"lib\\fonts\\454577c22304619db035.ttf","12":"lib\\fonts\\52ac8f3034507f1d9e53.ttf","13":"lib\\fonts\\05b618077343fbbd92b7.ttf","14":"lib\\fonts\\4bb6ac751d1c5478ff3a.woff2","15":"lib\\media\\874d8b8e340f75575caa.svg","16":"lib\\media\\3d6c1bdc4d87cde4de67.svg","17":"lib\\html\\file-tree.html","18":"lib\\scripts\\webpage.js","19":"lib\\scripts\\graph-view.js","20":"lib\\scripts\\graph-wasm.js","21":"lib\\scripts\\graph-render-worker.js","22":"lib\\scripts\\tinycolor.js","23":"lib\\scripts\\pixi.js","24":"lib\\scripts\\minisearch.js","25":"lib\\media\\favicon.png","26":"lib\\scripts\\graph-data.js","27":"lib\\styles\\obsidian.css","28":"lib\\styles\\other-plugins.css","29":"lib\\styles\\theme.css","30":"lib\\styles\\global-variable-styles.css","31":"lib\\styles\\supported-plugins.css","32":"lib\\styles\\main-styles.css","33":"lib\\metadata.json","34":"非模态分割/论文：image-amodal-completion-_a-survey.html"},"fieldIds":{"path":0,"title":1,"content":2,"tags":3,"headers":4},"fieldLength":{"1":[4,2,1,1,1],"2":[4,1,1,1,1],"3":[4,1,1,1,1],"4":[4,1,1,1,1],"5":[4,1,1,1,1],"6":[4,1,1,1,1],"7":[4,1,1,1,1],"8":[4,1,1,1,1],"9":[4,1,1,1,1],"10":[4,1,1,1,1],"11":[4,1,1,1,1],"12":[4,1,1,1,1],"13":[4,1,1,1,1],"14":[4,1,1,1,1],"15":[4,1,1,1,1],"16":[4,1,1,1,1],"17":[4,2,1,1,1],"18":[4,1,1,1,1],"19":[5,2,1,1,1],"20":[5,2,1,1,1],"21":[6,3,1,1,1],"22":[4,1,1,1,1],"23":[4,1,1,1,1],"24":[4,1,1,1,1],"25":[4,1,1,1,1],"26":[5,2,1,1,1],"27":[4,1,1,1,1],"28":[5,2,1,1,1],"29":[4,1,1,1,1],"30":[5,3,1,1,1],"31":[5,2,1,1,1],"32":[4,2,1,1,1],"33":[3,1,1,1,1],"34":[8,6,717,1,69]},"averageFieldLength":[4.323529411764706,1.5,22.058823529411764,1,2.999999999999999],"storedFields":{"1":{"path":"lib\\scripts\\graph-wasm.wasm","title":"graph-wasm","tags":[],"headers":[]},"2":{"path":"lib\\fonts\\94f2f163d4b698242fef.otf","title":"94f2f163d4b698242fef","tags":[],"headers":[]},"3":{"path":"lib\\fonts\\72505e6a122c6acd5471.woff2","title":"72505e6a122c6acd5471","tags":[],"headers":[]},"4":{"path":"lib\\fonts\\2d5198822ab091ce4305.woff2","title":"2d5198822ab091ce4305","tags":[],"headers":[]},"5":{"path":"lib\\fonts\\c8ba52b05a9ef10f4758.woff2","title":"c8ba52b05a9ef10f4758","tags":[],"headers":[]},"6":{"path":"lib\\fonts\\cb10ffd7684cd9836a05.woff2","title":"cb10ffd7684cd9836a05","tags":[],"headers":[]},"7":{"path":"lib\\fonts\\b5f0f109bc88052d4000.woff2","title":"b5f0f109bc88052d4000","tags":[],"headers":[]},"8":{"path":"lib\\fonts\\cbe0ae49c52c920fd563.woff2","title":"cbe0ae49c52c920fd563","tags":[],"headers":[]},"9":{"path":"lib\\fonts\\535a6cf662596b3bd6a6.woff2","title":"535a6cf662596b3bd6a6","tags":[],"headers":[]},"10":{"path":"lib\\fonts\\70cc7ff27245e82ad414.ttf","title":"70cc7ff27245e82ad414","tags":[],"headers":[]},"11":{"path":"lib\\fonts\\454577c22304619db035.ttf","title":"454577c22304619db035","tags":[],"headers":[]},"12":{"path":"lib\\fonts\\52ac8f3034507f1d9e53.ttf","title":"52ac8f3034507f1d9e53","tags":[],"headers":[]},"13":{"path":"lib\\fonts\\05b618077343fbbd92b7.ttf","title":"05b618077343fbbd92b7","tags":[],"headers":[]},"14":{"path":"lib\\fonts\\4bb6ac751d1c5478ff3a.woff2","title":"4bb6ac751d1c5478ff3a","tags":[],"headers":[]},"15":{"path":"lib\\media\\874d8b8e340f75575caa.svg","title":"874d8b8e340f75575caa","tags":[],"headers":[]},"16":{"path":"lib\\media\\3d6c1bdc4d87cde4de67.svg","title":"3d6c1bdc4d87cde4de67","tags":[],"headers":[]},"17":{"path":"lib\\html\\file-tree.html","title":"file-tree","tags":[],"headers":[]},"18":{"path":"lib\\scripts\\webpage.js","title":"webpage","tags":[],"headers":[]},"19":{"path":"lib\\scripts\\graph-view.js","title":"graph-view","tags":[],"headers":[]},"20":{"path":"lib\\scripts\\graph-wasm.js","title":"graph-wasm","tags":[],"headers":[]},"21":{"path":"lib\\scripts\\graph-render-worker.js","title":"graph-render-worker","tags":[],"headers":[]},"22":{"path":"lib\\scripts\\tinycolor.js","title":"tinycolor","tags":[],"headers":[]},"23":{"path":"lib\\scripts\\pixi.js","title":"pixi","tags":[],"headers":[]},"24":{"path":"lib\\scripts\\minisearch.js","title":"minisearch","tags":[],"headers":[]},"25":{"path":"lib\\media\\favicon.png","title":"favicon","tags":[],"headers":[]},"26":{"path":"lib\\scripts\\graph-data.js","title":"graph-data","tags":[],"headers":[]},"27":{"path":"lib\\styles\\obsidian.css","title":"obsidian","tags":[],"headers":[]},"28":{"path":"lib\\styles\\other-plugins.css","title":"other-plugins","tags":[],"headers":[]},"29":{"path":"lib\\styles\\theme.css","title":"theme","tags":[],"headers":[]},"30":{"path":"lib\\styles\\global-variable-styles.css","title":"global-variable-styles","tags":[],"headers":[]},"31":{"path":"lib\\styles\\supported-plugins.css","title":"supported-plugins","tags":[],"headers":[]},"32":{"path":"lib\\styles\\main-styles.css","title":"main-styles","tags":[],"headers":[]},"33":{"path":"lib\\metadata.json","title":"metadata","tags":[],"headers":[]},"34":{"path":"非模态分割/论文：image-amodal-completion-_a-survey.html","title":"论文：Image amodal completion _A survey","tags":[],"headers":["论文：Image amodal completion _A survey","1. Introduction","2.Taxonomy of problems","1. Amodal Shape Completion（非模态形状补全）","2. Amodal Appearance Completion（非模态外观补全）","3. Order Perception（顺序感知）","3.Datasets and evaluation","3.1Data collection","1. **Manual Annotation（手动标注）**","2. **Clip-art-based Image Composition（基于剪贴画的图像合成）**","3. **Synthetic 2D Images from 3D Scenes（基于合成场景的2D图像生成）**","4. **总结**","3.2 Datasets","1. **数据集的分类与应用场景**","2. **Common Objects Datasets（通用物体数据集）**","3. **Vehicle Datasets（车辆数据集）**","4. **Specialized Datasets（专用数据集：人体、室内场景等）**","5. **总结**","3.3Evaluation metrics and latest benchmark results on the amodal datasets（评估指标与最新基准结果）","3.3.1 Amodal Shape Completion","3.3.2 Amodal Appearance Completion","3.3.3 Order Perception","4. 应用总结","5.Open issues and future directions"]}},"dirtCount":0,"index":[["json",{"0":{"33":1}}],["js",{"0":{"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"26":1}}],["874d8b8e340f75575caa",{"0":{"15":1},"1":{"15":1}}],["70cc7ff27245e82ad414",{"0":{"10":1},"1":{"10":1}}],["72505e6a122c6acd5471",{"0":{"3":1},"1":{"3":1}}],["worker",{"0":{"21":1},"1":{"21":1}}],["woff2",{"0":{"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"14":1}}],["webpage",{"0":{"18":1},"1":{"18":1}}],["wasm",{"0":{"1":2,"20":1},"1":{"1":1,"20":1}}],["94f2f163d4b698242fef",{"0":{"2":1},"1":{"2":1}}],["91",{"2":{"34":1}}],["语义分割和深度估计等其他任务的结合具有很大的潜力",{"2":{"34":1}}],["与其他任务或上下文的集成",{"2":{"34":1}}],["尽管目前在amodal补全的理论研究中取得了较大进展",{"2":{"34":1}}],["尽管现有的研究在图像amodal补全领域取得了显著进展",{"2":{"34":1}}],["实时模型",{"2":{"34":1}}],["一致的性能度量标准",{"2":{"34":1}}],["一些研究将场景划分为前景和背景两个层",{"2":{"34":1}}],["一些早期的研究尝试使用几何模型",{"2":{"34":1}}],["联合解决多个子问题",{"2":{"34":1}}],["然而",{"2":{"34":1}}],["然后通过改变视角来生成不同的",{"2":{"34":1}}],["然后生成相应的",{"2":{"34":1}}],["然后将这些图像块叠加到另一幅目标图像中",{"2":{"34":1}}],["然后在候选区域内进行像素级分割",{"2":{"34":1}}],["目前对于各个amodal补全任务缺乏一致的评价标准",{"2":{"34":1}}],["目前大多数amodal补全的结果都仅限于二维表示",{"2":{"34":1}}],["目标",{"2":{"34":3}}],["更好的可视化表示",{"2":{"34":1}}],["未来需要针对每个任务制定统一的性能评估标准",{"2":{"34":1}}],["未来的研究可以探索多任务联合的模型设计",{"2":{"34":1}}],["未来的研究可能考虑将这些信息构建成2",{"2":{"34":1}}],["未来的研究应重点考虑如何在保持模型性能的同时",{"2":{"34":1}}],["未来的研究方向可能集中于阐明子问题间的相互依赖关系",{"2":{"34":1}}],["未来研究应探索如何在形状补全",{"2":{"34":1}}],["未来可能需要开发更真实的数据集",{"2":{"34":1}}],["合理的补全方式可能有多种不同可能性",{"2":{"34":1}}],["合成室内场景中生成",{"2":{"34":1}}],["合成场景的构建通常需要复杂的3d建模技术和渲染过程",{"2":{"34":1}}],["合成场景中可以任意控制物体的姿态",{"2":{"34":1}}],["合成的",{"2":{"34":1}}],["合成图像的视觉效果和细节可能与真实场景存在较大差距",{"2":{"34":1}}],["合成图像的逼真度和多样性不足",{"2":{"34":1}}],["合成图像可能会因为拼接过程而出现不自然的边界或纹理伪影",{"2":{"34":1}}],["当只有部分物体可见时",{"2":{"34":1}}],["输出结果的多样性",{"2":{"34":1}}],["开发能够完整展示物体不可见部分的真实数据集仍然是一项待解决的挑战",{"2":{"34":1}}],["对于遮挡物体的不可见部分",{"2":{"34":1}}],["对于不同的研究任务",{"2":{"34":1}}],["现有amodal数据集的标注主要依赖于人工推测",{"2":{"34":1}}],["现有的方法能够通过将已有的",{"2":{"34":1}}],["视图",{"2":{"34":1}}],["至关重要",{"2":{"34":1}}],["novel",{"2":{"34":1}}],["noise",{"2":{"34":1}}],["新视角合成",{"2":{"34":1}}],["避免因仅依赖可见部分而导致的错误识别",{"2":{"34":1}}],["进行识别",{"2":{"34":1}}],["进行非模态外观补全",{"2":{"34":1}}],["机器人经常需要应对被遮挡的目标物体",{"2":{"34":1}}],["机器人抓取系统",{"2":{"34":2}}],["能够有效提升产品展示效果",{"2":{"34":1}}],["能够提供高质量的标注数据",{"2":{"34":1}}],["技术能够移除用户不希望看到的障碍物",{"2":{"34":1}}],["技术的补充",{"2":{"34":1}}],["技术通过去除场景中的不必要实体来提升用户体验",{"2":{"34":1}}],["增强现实",{"2":{"34":1}}],["是",{"2":{"34":1}}],["是最常用的指标",{"2":{"34":1}}],["同时",{"2":{"34":1}}],["同时还提供了物体间的层次顺序信息",{"2":{"34":1}}],["同样基于",{"2":{"34":1}}],["补全能够生成遮挡物后方的完整视角信息",{"2":{"34":1}}],["补全能够帮助自动驾驶系统预测物体的完整形状",{"2":{"34":1}}],["补全技术能够帮助机器人理解遮挡关系和目标物体的形状",{"2":{"34":1}}],["补全技术还在隐私保护应用中大有作为",{"2":{"34":1}}],["补全技术在许多实际应用中具有重要价值",{"2":{"34":1}}],["补全任务能够将场景中的物体与背景进行分离",{"2":{"34":1}}],["掩码",{"2":{"34":1}}],["因为这要求标注者对不可见部分进行合理推测",{"2":{"34":1}}],["因此",{"2":{"34":2}}],["因此在评估时需要考虑形状",{"2":{"34":1}}],["因此这些数据集主要用于训练和评估车辆形状和外观的补全模型",{"2":{"34":1}}],["因此可以轻松获取物体的完整形状和外观",{"2":{"34":1}}],["因此可以生成高质量的标注数据集",{"2":{"34":1}}],["因此可以在合成图像中准确地提供被遮挡部分的外观数据",{"2":{"34":1}}],["自动驾驶系统需要对道路上的各种物体",{"2":{"34":1}}],["自动驾驶",{"2":{"34":1}}],["自动驾驶和新视角合成等场景",{"2":{"34":1}}],["自动生成",{"2":{"34":1}}],["减弱现实",{"2":{"34":2}}],["涵盖了自动生成",{"2":{"34":1}}],["应用于场景重建和虚拟现实中",{"2":{"34":1}}],["应用总结",{"2":{"34":1},"4":{"34":1}}],["应用场景",{"2":{"34":8}}],["距离",{"2":{"34":1}}],["还可采用",{"2":{"34":1}}],["此外",{"2":{"34":1}}],["均方根误差",{"2":{"34":1}}],["成对深度顺序精度",{"2":{"34":1}}],["05b618077343fbbd92b7",{"0":{"13":1},"1":{"13":1}}],["0",{"2":{"34":1}}],["达到了",{"2":{"34":1}}],["评估中",{"2":{"34":1}}],["评估指标与最新基准结果",{"2":{"34":2},"4":{"34":1}}],["研究任务包括遮挡顺序",{"2":{"34":1}}],["研究者常采用以下指标",{"2":{"34":1}}],["研究人员首先将某些目标物体",{"2":{"34":1}}],["最高分为",{"2":{"34":1}}],["最传统的标注方式",{"2":{"34":1}}],["不同方法取得的",{"2":{"34":1}}],["不结合目标检测的非模态实例分割",{"2":{"34":1}}],["结果",{"2":{"34":1}}],["结合注意力机制来重建物体的外观",{"2":{"34":1}}],["结合目标检测的非模态实例分割",{"2":{"34":1}}],["任务中测试多种方法的表现",{"2":{"34":1}}],["任务中常用的评估指标以及现有数据集上的基准模型表现",{"2":{"34":1}}],["两个数据集来评估基准表现",{"2":{"34":1}}],["及多种基于阈值的准确性指标",{"2":{"34":1}}],["及",{"2":{"34":2}}],["及物体间的",{"2":{"34":1}}],["召回率",{"2":{"34":1}}],["精确率",{"2":{"34":1}}],["精确形状标注的任务",{"2":{"34":1}}],["union",{"2":{"34":1}}],["unet",{"2":{"34":1}}],["常用评估指标包括",{"2":{"34":1}}],["以便更好地进行不同方法间的比较",{"2":{"34":1}}],["以下是对这些挑战以及未来研究方向的总结",{"2":{"34":1}}],["以下是对主要指标的详细描述",{"2":{"34":1}}],["以及更复杂的视觉感知度量标准",{"2":{"34":1}}],["以及",{"2":{"34":2}}],["以及遮挡顺序标注",{"2":{"34":1}}],["以及遮挡关系",{"2":{"34":1}}],["以及合成遮挡物体的位置和类别",{"2":{"34":1}}],["以及每类物体的非模态分割掩码",{"2":{"34":1}}],["顺序推理",{"2":{"34":1}}],["顺序感知可以帮助提升形状和外观补全的精度",{"2":{"34":1}}],["顺序感知是指理解物体在场景中的相互遮挡关系",{"2":{"34":1}}],["顺序感知",{"2":{"34":1},"4":{"34":1}}],["形状补全",{"2":{"34":1}}],["形成遮挡关系",{"2":{"34":1}}],["根据任务目标和具体应用场景",{"2":{"34":1}}],["根据是否结合目标检测技术",{"2":{"34":1}}],["帮助他们更好地理解现有模型的优劣",{"2":{"34":1}}],["部分研究已经尝试了对多个子问题的联合解决",{"2":{"34":1}}],["部分",{"2":{"34":1}}],["可用于不同任务的模型训练和评估",{"2":{"34":1}}],["可以更自然地填充被遮挡的背景部分",{"2":{"34":1}}],["可以根据任务需求选择合适的数据集构建方法",{"2":{"34":1}}],["可以辅助非模态形状和外观补全任务",{"2":{"34":1}}],["可以自动生成物体的非模态分割掩码和完整外观",{"2":{"34":1}}],["可以提供复杂场景中不同物体类别的完整形状标注",{"2":{"34":1}}],["可以将这些方法分为两大类",{"2":{"34":1}}],["52ac8f3034507f1d9e53",{"0":{"12":1},"1":{"12":1}}],["535a6cf662596b3bd6a6",{"0":{"9":1},"1":{"9":1}}],["5d或3d表示",{"2":{"34":1}}],["5",{"2":{"34":2},"4":{"34":2}}],["为了降低标注成本",{"2":{"34":1}}],["为了评估图像的生成质量",{"2":{"34":1}}],["为了实现这一目标",{"2":{"34":1}}],["为不同场景和任务提供了详细的数据集参考",{"2":{"34":1}}],["为特定任务",{"2":{"34":1}}],["行人和障碍物",{"2":{"34":1}}],["行人",{"2":{"34":1}}],["建筑物",{"2":{"34":1}}],["类",{"2":{"34":2}}],["类别特定的非模态标注",{"2":{"34":1}}],["车辆重叠等",{"2":{"34":1}}],["车辆数据集专注于交通场景中车辆的非模态补全",{"2":{"34":1}}],["车辆数据集",{"2":{"34":2},"4":{"34":1}}],["特别是在移除大型遮挡物时",{"2":{"34":1}}],["特点",{"2":{"34":2}}],["特定类别的外观补全",{"2":{"34":1}}],["favicon",{"0":{"25":1},"1":{"25":1}}],["fonts",{"0":{"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1}}],["follmann",{"2":{"34":3}}],["future",{"2":{"34":1},"4":{"34":1}}],["fréchet",{"2":{"34":1}}],["file",{"0":{"17":1},"1":{"17":1}}],["fid",{"2":{"34":1}}],["fingscheidt",{"2":{"34":1}}],["f1",{"2":{"34":2}}],["完整",{"2":{"34":1}}],["完整的",{"2":{"34":1}}],["相对误差",{"2":{"34":1}}],["相对遮挡顺序",{"2":{"34":1}}],["相比手动标注",{"2":{"34":1}}],["所有物体被人工合成遮挡关系",{"2":{"34":1}}],["模拟复杂交通场景中的遮挡关系",{"2":{"34":1}}],["模态分割掩码",{"2":{"34":1}}],["模型的性能通常通过以下几种主要评估指标来衡量",{"2":{"34":1}}],["模型生成的",{"2":{"34":1}}],["模型",{"2":{"34":1}}],["模型通过输入图像块预测被遮挡物体的非模态掩码",{"2":{"34":1}}],["模型经过扩展后可以实现非模态形状补全",{"2":{"34":1}}],["仅包含",{"2":{"34":1}}],["仅提供物体形状和遮挡顺序信息",{"2":{"34":1}}],["深度关系",{"2":{"34":1}}],["深度顺序",{"2":{"34":1}}],["深度信息",{"2":{"34":1}}],["深度信息和",{"2":{"34":1}}],["双向遮挡顺序",{"2":{"34":1}}],["用于测试不同模型的顺序恢复能力",{"2":{"34":1}}],["用于人体姿态补全和遮挡推理任务",{"2":{"34":1}}],["用于复杂交通场景中不同类别的遮挡与顺序推理任务",{"2":{"34":1}}],["用于训练车辆的外观补全模型",{"2":{"34":1}}],["用于多物体类别的非模态分割和类别识别任务",{"2":{"34":1}}],["用于模型在通用场景中的训练和评估",{"2":{"34":1}}],["用于恢复被遮挡车辆的外观",{"2":{"34":1}}],["多场景的标注",{"2":{"34":1}}],["该技术通过填补被遮挡区域",{"2":{"34":1}}],["该任务中使用的主要数据集包括",{"2":{"34":1}}],["该任务的重点在于预测物体不可见部分的外观和细节纹理",{"2":{"34":1}}],["该部分为研究人员提供了一个系统的框架",{"2":{"34":1}}],["该部分将现有数据集分为三大类",{"2":{"34":1}}],["该数据集用于超市商品及日常用品的遮挡关系分析与非模态分割",{"2":{"34":1}}],["该数据集可用于通用物体的非模态形状补全及遮挡顺序推理任务",{"2":{"34":1}}],["该类数据集旨在提供多类别",{"2":{"34":1}}],["动物",{"2":{"34":1}}],["室内场景等",{"2":{"34":2},"4":{"34":1}}],["专用数据集",{"2":{"34":2},"4":{"34":1}}],["通常",{"2":{"34":1}}],["通用物体数据集",{"2":{"34":2},"4":{"34":1}}],["通过合成方法生成",{"2":{"34":1}}],["通过合成方式可以快速生成大规模的非模态数据集",{"2":{"34":1}}],["通过将",{"2":{"34":1}}],["通过将现有图像中剪切出的物体片段",{"2":{"34":1}}],["通过叠加超市商品的图像片段生成了大量具有非模态分割掩码的合成图像",{"2":{"34":1}}],["通过剪贴画合成的方式",{"2":{"34":1}}],["通过推测物体间的遮挡关系",{"2":{"34":1}}],["通过迭代地调整边界框",{"2":{"34":1}}],["分数有所不同",{"2":{"34":1}}],["分别测试不同模型在生成图像外观上的表现",{"2":{"34":1}}],["分别在",{"2":{"34":1}}],["分别基于",{"2":{"34":1}}],["分别是",{"2":{"34":1}}],["分为以下几种类型",{"2":{"34":1}}],["适用于复杂室内场景中的物体补全与遮挡顺序推理",{"2":{"34":1}}],["适用于城市交通场景中的车辆形状补全和遮挡顺序推理任务",{"2":{"34":1}}],["适用于大规模数据集的生成",{"2":{"34":1}}],["适用于需要高质量",{"2":{"34":1}}],["总结",{"2":{"34":2},"4":{"34":2}}],["4bb6ac751d1c5478ff3a",{"0":{"14":1},"1":{"14":1}}],["454577c22304619db035",{"0":{"11":1},"1":{"11":1}}],["4",{"2":{"34":4},"4":{"34":3}}],["环境模拟生成了大量室内和室外场景的图像",{"2":{"34":1}}],["环境中构建一个包含多个物体的场景",{"2":{"34":1}}],["view",{"0":{"19":1},"1":{"19":1},"2":{"34":1}}],["variable",{"0":{"30":1},"1":{"30":1}}],["valada",{"2":{"34":1}}],["vae",{"2":{"34":1}}],["vehicle",{"2":{"34":3},"4":{"34":1}}],["v",{"2":{"34":1}}],["vos",{"2":{"34":1}}],["导致模型在真实场景中的泛化能力不足",{"2":{"34":1}}],["物体隐藏部分的多样性是amodal补全任务的自然问题",{"2":{"34":1}}],["物体移除或复制",{"2":{"34":1}}],["物体间的空间关系等",{"2":{"34":1}}],["物体中心表示",{"2":{"34":1}}],["位置",{"2":{"34":1}}],["首先在",{"2":{"34":1}}],["首先使用目标检测方法获取目标所在区域",{"2":{"34":1}}],["外观补全以及顺序感知任务中更好地表示这些多样性",{"2":{"34":1}}],["外观补全",{"2":{"34":1}}],["外观及遮挡关系",{"2":{"34":1}}],["外观及遮挡顺序",{"2":{"34":1}}],["外观",{"2":{"34":6}}],["外观信息",{"2":{"34":1}}],["图像",{"2":{"34":3}}],["图层顺序任务中使用",{"2":{"34":1}}],["图层顺序主要用于确定物体的深度关系",{"2":{"34":1}}],["图层顺序",{"2":{"34":2}}],["场景编辑和重构",{"2":{"34":2}}],["场景的合成图像",{"2":{"34":1}}],["场景能够精确地控制物体的遮挡关系",{"2":{"34":1}}],["场景",{"2":{"34":1}}],["影响训练效果",{"2":{"34":1}}],["难以模拟复杂真实场景中的光照变化和深度关系",{"2":{"34":1}}],["难以处理复杂背景中的多物体遮挡",{"2":{"34":1}}],["难以应用于复杂场景",{"2":{"34":1}}],["只能处理通过剪贴画叠加产生的遮挡",{"2":{"34":1}}],["提高其实时处理能力",{"2":{"34":1}}],["提供室内场景中物体的",{"2":{"34":1}}],["提供详细标注",{"2":{"34":1}}],["提供城市交通场景中的",{"2":{"34":1}}],["提供城市交通场景中车辆和行人的",{"2":{"34":1}}],["提供被遮挡车辆的",{"2":{"34":1}}],["提供车辆和行人的",{"2":{"34":1}}],["提供超市商品的非模态掩码",{"2":{"34":1}}],["提供每个物体的类别标签",{"2":{"34":1}}],["提供",{"2":{"34":3}}],["提供了比人工标注更细致和自然的结果",{"2":{"34":1}}],["提供了丰富的非模态形状和外观标注",{"2":{"34":1}}],["提供了被遮挡区域的完整外观标注",{"2":{"34":1}}],["提供丰富的场景信息",{"2":{"34":1}}],["提出了一种用于人体外观补全的",{"2":{"34":1}}],["提出了一个",{"2":{"34":1}}],["提出的",{"2":{"34":1}}],["由于该领域尚处于早期阶段",{"2":{"34":1}}],["由于非模态补全涉及到恢复被遮挡区域的物体形状",{"2":{"34":1}}],["由于车辆类别的形状和结构相对稳定",{"2":{"34":1}}],["由于这些图像是从",{"2":{"34":1}}],["由于物体是从原图中剪切出来的",{"2":{"34":1}}],["由于是由人类标注者依据真实的视觉经验进行标注",{"2":{"34":1}}],["人类等",{"2":{"34":1}}],["人类标注者在预测被遮挡区域时通常具有较高的一致性",{"2":{"34":1}}],["人体姿态和外观的非模态分割掩码及外观信息",{"2":{"34":1}}],["人体",{"2":{"34":2},"4":{"34":1}}],["人物",{"2":{"34":1}}],["叠加到目标图像上",{"2":{"34":1}}],["基于",{"2":{"34":7}}],["基于合成场景的2d图像生成",{"2":{"34":1},"4":{"34":1}}],["基于剪贴画的图像合成是一种较为低成本的方式",{"2":{"34":1}}],["基于剪贴画的图像合成",{"2":{"34":2},"4":{"34":1}}],["基于深度学习的",{"2":{"34":1}}],["生成",{"2":{"34":1}}],["生成数据集的成本较高",{"2":{"34":1}}],["生成了被遮挡车辆的合成图像",{"2":{"34":1}}],["生成了非模态分割掩码和相对遮挡顺序信息",{"2":{"34":1}}],["生成物体的分割掩码",{"2":{"34":1}}],["在实际环境中",{"2":{"34":1}}],["在应用场景中",{"2":{"34":1}}],["在非模态补全任务中",{"2":{"34":1}}],["在合成的室内场景中生成了具有多遮挡关系的图像",{"2":{"34":1}}],["在",{"2":{"34":4}}],["在复杂场景中效果较差",{"2":{"34":1}}],["qi",{"2":{"34":2}}],["kitti",{"2":{"34":5}}],["kins",{"2":{"34":5}}],["ke",{"2":{"34":1}}],["数据集非常昂贵且耗时",{"2":{"34":1}}],["数据集包括",{"2":{"34":1}}],["数据集上达到",{"2":{"34":1}}],["数据集上",{"2":{"34":1}}],["数据集上进行了车辆和行人的手动标注",{"2":{"34":1}}],["数据集进行扩展",{"2":{"34":1}}],["数据集进行生成",{"2":{"34":1}}],["数据集生成",{"2":{"34":1}}],["数据集的交通场景图像",{"2":{"34":1}}],["数据集的分类与应用场景",{"2":{"34":1},"4":{"34":1}}],["数据集中的物体剪贴到车辆图像上",{"2":{"34":1}}],["数据集中部分图像的非模态分割掩码和物体间的遮挡顺序",{"2":{"34":1}}],["数据集",{"2":{"34":9}}],["代表性数据集",{"2":{"34":3}}],["无法提供被遮挡区域的",{"2":{"34":1}}],["局限性",{"2":{"34":5}}],["标注具有一定的主观性",{"2":{"34":1}}],["标注转化为伪",{"2":{"34":1}}],["标注",{"2":{"34":3}}],["标注包括",{"2":{"34":1}}],["标注精细度较高",{"2":{"34":1}}],["标注内容较为单一",{"2":{"34":1}}],["标注了物体之间的",{"2":{"34":1}}],["标注类型",{"2":{"34":10}}],["标注成本低",{"2":{"34":1}}],["标注成本高",{"2":{"34":1}}],["标注结果高度精确且具有多样性",{"2":{"34":1}}],["标注结果通常仅限于物体的非模态形状",{"2":{"34":1}}],["标注结果往往具有较高的质量和一致性",{"2":{"34":1}}],["标注者之间的意见可能会有差异",{"2":{"34":1}}],["标注者通常需要通过想象物体的被遮挡部分来标记物体的完整轮廓",{"2":{"34":1}}],["优点",{"2":{"34":3}}],["的感知与预测",{"2":{"34":1}}],["的得分",{"2":{"34":1}}],["的不同指标",{"2":{"34":1}}],["的图像块从背景中剪切出来",{"2":{"34":1}}],["的标注数据集",{"2":{"34":1}}],["的研究表明",{"2":{"34":1}}],["的框架",{"2":{"34":1}}],["但实际应用仍需要能够在复杂场景中实时处理的模型",{"2":{"34":1}}],["但很少有研究对联合解决这些问题的重要性进行深入讨论",{"2":{"34":1}}],["但在实际应用中仍然存在许多挑战",{"2":{"34":1}}],["但在视觉效果上可能与真实场景存在差距",{"2":{"34":1}}],["但专注于物体间的几何顺序标注",{"2":{"34":1}}],["但为物体提供了",{"2":{"34":1}}],["但生成图像的质量受限于拼接过程",{"2":{"34":1}}],["但成本高昂",{"2":{"34":1}}],["但其生成的图像通常不够真实",{"2":{"34":1}}],["但其缺点在于标注成本高且耗时耗力",{"2":{"34":1}}],["但",{"2":{"34":1}}],["将物体看作完全可见的形式进行标注",{"2":{"34":1}}],["将重叠区域划分为不同的遮挡层",{"2":{"34":1}}],["具体描述",{"2":{"34":3}}],["具有较高的准确性和一致性",{"2":{"34":1}}],["并利用其他任务的优势来提升amodal补全的表现",{"2":{"34":1}}],["并通过消融实验验证联合解决方案的效果",{"2":{"34":1}}],["并考虑多种可能的结果模式",{"2":{"34":1}}],["并采用新的成像手段",{"2":{"34":1}}],["并避免在操作过程中发生碰撞",{"2":{"34":1}}],["并填补缺失的图像信息",{"2":{"34":1}}],["并为未来研究提供参考",{"2":{"34":1}}],["并评估模型对复杂遮挡场景的泛化能力",{"2":{"34":1}}],["并详细分析了每种方式的优点和局限性",{"2":{"34":1}}],["并对其中的物体进行了完整标注",{"2":{"34":1}}],["并且提供了被遮挡物体的完整形状或外观标注",{"2":{"34":1}}],["并且能够提供物体间的复杂交互信息",{"2":{"34":1}}],["并且容易产生伪影",{"2":{"34":1}}],["并提供了车辆的完整外观标注",{"2":{"34":1}}],["并手动标注这些不可见区域的轮廓或外观",{"2":{"34":1}}],["并依此推测物体的排列顺序",{"2":{"34":1}}],["手动标注了",{"2":{"34":1}}],["手动标注数据集需要投入大量的人工资源和时间",{"2":{"34":1}}],["手动标注是指通过人工方式对图像进行标注",{"2":{"34":1}}],["手动标注",{"2":{"34":3},"4":{"34":1}}],["或特定场景",{"2":{"34":1}}],["或相应的边界框",{"2":{"34":1}}],["或使用多图层结构表示更复杂的物体深度关系",{"2":{"34":1}}],["或深度关系",{"2":{"34":1}}],["dr",{"2":{"34":3}}],["directions",{"2":{"34":1},"4":{"34":1}}],["diminished",{"2":{"34":2}}],["distance",{"2":{"34":1}}],["data",{"0":{"26":1},"1":{"26":1}}],["dataset",{"2":{"34":2}}],["datasets",{"2":{"34":11},"4":{"34":6}}],["damerow",{"2":{"34":1}}],["densely",{"2":{"34":1}}],["depth",{"2":{"34":3}}],["d2s",{"2":{"34":3}}],["dhamo",{"2":{"34":1}}],["前景和背景的关系",{"2":{"34":1}}],["从而提供更直观的结果",{"2":{"34":1}}],["从而提升驾驶安全性",{"2":{"34":1}}],["从而在复杂环境中更好地规划抓取策略",{"2":{"34":1}}],["从而使场景编辑更为方便",{"2":{"34":1}}],["从而生成更加完整的",{"2":{"34":1}}],["从而生成高质量的",{"2":{"34":1}}],["从而生成具有高度准确性的标注数据",{"2":{"34":1}}],["从而生成非模态分割掩码",{"2":{"34":1}}],["从而获得完整的物体标注",{"2":{"34":1}}],["从而适用于非模态外观补全任务",{"2":{"34":1}}],["从而模拟被遮挡的场景",{"2":{"34":1}}],["从而为模型提供精确的非模态分割掩码",{"2":{"34":1}}],["从而分离遮挡物和被遮挡物",{"2":{"34":1}}],["从而更好地理解场景中的物体大小和相对深度",{"2":{"34":1}}],["global",{"0":{"30":1},"1":{"30":1}}],["graph",{"0":{"1":1,"19":1,"20":1,"21":1,"26":1},"1":{"1":1,"19":1,"20":1,"21":1,"26":1}}],["gta",{"2":{"34":1}}],["gcn",{"2":{"34":1}}],["gan",{"2":{"34":1}}],["b5f0f109bc88052d4000",{"0":{"7":1},"1":{"7":1}}],["benchmark",{"2":{"34":2},"4":{"34":1}}],["bdd100k",{"2":{"34":2}}],["breitenstein",{"2":{"34":1}}],["bidirectional",{"2":{"34":1}}],["bcnet",{"2":{"34":2}}],["b",{"2":{"34":1}}],["based",{"2":{"34":2},"4":{"34":1}}],["遮挡关系和标注精细度上各有侧重",{"2":{"34":1}}],["遮挡关系和光照条件",{"2":{"34":1}}],["遮挡物体",{"2":{"34":1}}],["遮挡顺序等多个方面的指标",{"2":{"34":1}}],["遮挡顺序等",{"2":{"34":1}}],["遮挡顺序",{"2":{"34":4}}],["levenstein",{"2":{"34":1}}],["lee",{"2":{"34":1}}],["latest",{"2":{"34":2},"4":{"34":1}}],["labels",{"2":{"34":1}}],["layer",{"2":{"34":3}}],["lib",{"0":{"1":1,"2":1,"3":1,"4":1,"5":1,"6":1,"7":1,"8":1,"9":1,"10":1,"11":1,"12":1,"13":1,"14":1,"15":1,"16":1,"17":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"25":1,"26":1,"27":1,"28":1,"29":1,"30":1,"31":1,"32":1,"33":1}}],["li",{"2":{"34":1}}],["plugins",{"0":{"28":1,"31":1},"1":{"28":1,"31":1}}],["png",{"0":{"25":1}}],["pixi",{"0":{"23":1},"1":{"23":1}}],["peak",{"2":{"34":1}}],["perception",{"2":{"34":2},"4":{"34":2}}],["psnr",{"2":{"34":2}}],["pcnet",{"2":{"34":1}}],["prior",{"2":{"34":2}}],["precision",{"2":{"34":4}}],["problems",{"2":{"34":1},"4":{"34":1}}],["problem",{"2":{"34":1}}],["pairwise",{"2":{"34":2}}],["parsing",{"2":{"34":1}}],["park",{"2":{"34":1}}],["panoptic",{"2":{"34":1}}],["patches",{"2":{"34":1}}],["35",{"2":{"34":2}}],["3evaluation",{"2":{"34":1},"4":{"34":1}}],["360",{"2":{"34":2}}],["3d6c1bdc4d87cde4de67",{"0":{"16":1},"1":{"16":1}}],["3d",{"2":{"34":8},"4":{"34":1}}],["3",{"2":{"34":16},"4":{"34":14}}],["来改进标注的准确性",{"2":{"34":1}}],["来计算预测顺序与真实顺序之间的最小操作次数",{"2":{"34":1}}],["来源",{"2":{"34":9}}],["来辅助形状和外观补全任务",{"2":{"34":1}}],["来生成物体的被遮挡部分的外观",{"2":{"34":1}}],["来推测被遮挡部分的形状",{"2":{"34":1}}],["针对成对物体实例的遮挡顺序",{"2":{"34":1}}],["针对遮挡形状的补全任务",{"2":{"34":1}}],["针对真实场景中较复杂的物体或背景进行外观补全",{"2":{"34":1}}],["针对某些特定类型的物体",{"2":{"34":1}}],["复杂场景的外观补全",{"2":{"34":1}}],["zheng",{"2":{"34":4}}],["zhou",{"2":{"34":3}}],["zhu",{"2":{"34":4}}],["而这些物体可能被部分遮挡",{"2":{"34":1}}],["而非完整的非模态分割信息",{"2":{"34":1}}],["而",{"2":{"34":1}}],["而不包含被遮挡部分的",{"2":{"34":1}}],["而不受遮挡的影响",{"2":{"34":1}}],["而不仅仅是物体轮廓",{"2":{"34":1}}],["而不依赖于目标检测框",{"2":{"34":1}}],["而不是仅仅关注可见部分的分割",{"2":{"34":1}}],["等人",{"2":{"34":2}}],["yan",{"2":{"34":3}}],["使用以下评估指标",{"2":{"34":1}}],["使用图卷积网络",{"2":{"34":1}}],["使用",{"2":{"34":2}}],["使用变分自编码器",{"2":{"34":1}}],["使得物体看起来完整且一致",{"2":{"34":1}}],["minisearch",{"0":{"24":1},"1":{"24":1}}],["miou",{"2":{"34":1}}],["mse",{"2":{"34":1}}],["media",{"0":{"15":1,"16":1,"25":1}}],["mean",{"2":{"34":4}}],["metadata",{"0":{"33":1},"1":{"33":1}}],["metrics",{"2":{"34":2},"4":{"34":1}}],["methods",{"2":{"34":1}}],["mohan",{"2":{"34":1}}],["modal",{"2":{"34":2}}],["monet",{"2":{"34":1}}],["main",{"0":{"32":1},"1":{"32":1}}],["map",{"2":{"34":4}}],["manual",{"2":{"34":1},"4":{"34":1}}],["malik",{"2":{"34":1}}],["masks",{"2":{"34":2}}],["mask",{"2":{"34":4}}],["主要使用",{"2":{"34":1}}],["主要讨论了图像非模态补全",{"2":{"34":1}}],["主要用于简单的玩具数据集",{"2":{"34":1}}],["主要采用以下几种方法",{"2":{"34":1}}],["tinycolor",{"0":{"22":1},"1":{"22":1}}],["tree",{"0":{"17":1},"1":{"17":1}}],["ttf",{"0":{"10":1,"11":1,"12":1,"13":1}}],["to",{"2":{"34":1}}],["toy",{"2":{"34":1}}],["theme",{"0":{"29":1},"1":{"29":1}}],["the",{"2":{"34":2},"4":{"34":1}}],["thing",{"2":{"34":1}}],["taxonomy",{"2":{"34":1},"4":{"34":1}}],["other",{"0":{"28":1},"1":{"28":1}}],["otf",{"0":{"2":1}}],["obsidian",{"0":{"27":1},"1":{"27":1}}],["objects",{"2":{"34":3},"4":{"34":1}}],["object",{"2":{"34":1}}],["open",{"2":{"34":1},"4":{"34":1}}],["orcnn",{"2":{"34":1}}],["ordering",{"2":{"34":2}}],["order",{"2":{"34":14},"4":{"34":2}}],["over",{"2":{"34":1}}],["ovd",{"2":{"34":2}}],["on",{"2":{"34":2},"4":{"34":1}}],["occluded",{"2":{"34":1}}],["occlusion",{"2":{"34":9}}],["大多数当前的非模态外观补全方法都依赖于从非模态形状补全中获得的形状掩码",{"2":{"34":1}}],["值",{"2":{"34":1}}],["即包含物体被遮挡部分的完整分割轮廓",{"2":{"34":1}}],["即掩码或轮廓",{"2":{"34":1}}],["即由人类标注者根据视觉感知能力来预测物体的被遮挡部分",{"2":{"34":1}}],["即",{"2":{"34":1}}],["直线和贝塞尔曲线",{"2":{"34":1}}],["直接在像素级别进行形状补全",{"2":{"34":1}}],["螺旋",{"2":{"34":1}}],["error",{"2":{"34":2}}],["evaluation",{"2":{"34":2},"4":{"34":1}}],["ehsani",{"2":{"34":1}}],["euler",{"2":{"34":1}}],["et",{"2":{"34":21}}],["如何更有效地展示额外推测的信息仍需要进一步研究",{"2":{"34":1}}],["如x射线",{"2":{"34":1}}],["如从单一视图合成三维图像",{"2":{"34":1}}],["如移除照片中的人群或车辆",{"2":{"34":1}}],["如室内环境",{"2":{"34":1}}],["如人体姿态补全或室内场景分割",{"2":{"34":1}}],["如人体",{"2":{"34":1}}],["如车辆",{"2":{"34":2}}],["如车辆或人体",{"2":{"34":1}}],["如道路",{"2":{"34":1}}],["如行人穿行",{"2":{"34":1}}],["如深度图",{"2":{"34":1}}],["如模拟街景或室内场景",{"2":{"34":1}}],["如物体",{"2":{"34":1}}],["如直线或圆形",{"2":{"34":1}}],["如",{"2":{"34":4}}],["如边界框",{"2":{"34":1}}],["几何形状补全方法",{"2":{"34":1}}],["逐步推测物体的完整形状",{"2":{"34":1}}],["方法在",{"2":{"34":1}}],["方法",{"2":{"34":2}}],["和图层顺序",{"2":{"34":1}}],["和物体间的",{"2":{"34":1}}],["和遮挡顺序",{"2":{"34":1}}],["和",{"2":{"34":12}}],["css",{"0":{"27":1,"28":1,"29":1,"30":1,"31":1,"32":1}}],["csdnet",{"2":{"34":2}}],["csd",{"2":{"34":3}}],["cbe0ae49c52c920fd563",{"0":{"8":1},"1":{"8":1}}],["cb10ffd7684cd9836a05",{"0":{"6":1},"1":{"6":1}}],["c8ba52b05a9ef10f4758",{"0":{"5":1},"1":{"5":1}}],["cityscapes",{"2":{"34":2}}],["cars",{"2":{"34":1}}],["category",{"2":{"34":1}}],["class",{"2":{"34":2}}],["cls",{"2":{"34":1}}],["clip",{"2":{"34":1},"4":{"34":1}}],["context",{"2":{"34":1}}],["common",{"2":{"34":3},"4":{"34":1}}],["composite",{"2":{"34":1}}],["composition",{"2":{"34":1},"4":{"34":1}}],["complex",{"2":{"34":1}}],["completion",{"0":{"34":1},"1":{"34":1},"2":{"34":7},"4":{"34":5}}],["coco",{"2":{"34":5}}],["cocoa",{"2":{"34":9}}],["collection",{"2":{"34":1},"4":{"34":1}}],["cgan",{"2":{"34":1}}],["centric",{"2":{"34":1}}],["cnn",{"2":{"34":1}}],["ratio",{"2":{"34":1}}],["root",{"2":{"34":1}}],["rmse",{"2":{"34":2}}],["rcnn",{"2":{"34":1}}],["render",{"0":{"21":1},"1":{"21":1}}],["reality",{"2":{"34":2}}],["rel",{"2":{"34":1}}],["relative",{"2":{"34":1}}],["recall",{"2":{"34":2}}],["results",{"2":{"34":2},"4":{"34":1}}],["representations",{"2":{"34":1}}],["rgb",{"2":{"34":9}}],["r",{"2":{"34":1}}],["例如移除敏感物体时",{"2":{"34":1}}],["例如日常用品",{"2":{"34":1}}],["例如汽车",{"2":{"34":1}}],["例如",{"2":{"34":8}}],["包括被遮挡车辆的形状",{"2":{"34":1}}],["包括被遮挡部分的形状推测",{"2":{"34":1}}],["包括可见和不可见部分",{"2":{"34":1}}],["其目标是预测一个实例的完整分割掩码",{"2":{"34":1}}],["这使得生成更接近真实情况的标注成为一个重要研究方向",{"2":{"34":1}}],["这对于新视角图像生成",{"2":{"34":1}}],["这对于例如虚拟家具展示等场景非常有用",{"2":{"34":1}}],["这些信息能够用于对象顺序的交换",{"2":{"34":1}}],["这些自动生成的掩码甚至在某些任务上超越了手动标注",{"2":{"34":1}}],["这些评估指标可分为针对",{"2":{"34":1}}],["这些数据集在标注类型",{"2":{"34":1}}],["这些数据集专注于特定类别",{"2":{"34":1}}],["这些数据集通常包含多种物体类别",{"2":{"34":1}}],["这些合成图像可以提供物体的非模态分割掩码",{"2":{"34":1}}],["这些方法通常需要使用合成数据进行训练",{"2":{"34":1}}],["这些方法通常只适用于简单形状",{"2":{"34":1}}],["这些方法主要在颜色对比度明显的简单背景下有效",{"2":{"34":1}}],["这种方式通过构建",{"2":{"34":1}}],["这种方法可以为模型提供大规模的非模态外观数据",{"2":{"34":1}}],["这种方法是图像非模态补全领域中最直接",{"2":{"34":1}}],["这一部分系统性地总结了图像非模态补全任务中常用的数据集生成方式",{"2":{"34":1}}],["这一方法通常用于生成非模态形状补全",{"2":{"34":1}}],["这一任务的目标是恢复物体的整体轮廓",{"2":{"34":1}}],["这是最常用的非模态形状补全技术",{"2":{"34":1}}],["非模态掩码",{"2":{"34":1}}],["非模态全景标注",{"2":{"34":1}}],["非模态外观补全的目标是恢复被遮挡部分的物体表面外观",{"2":{"34":1}}],["非模态外观补全",{"2":{"34":1},"4":{"34":1}}],["非模态实例分割掩码",{"2":{"34":1}}],["非模态实例分割",{"2":{"34":1}}],["非模态形状补全是指利用部分视觉证据推测物体的完整形状",{"2":{"34":1}}],["非模态形状补全",{"2":{"34":1},"4":{"34":1}}],["非模态分割掩码",{"2":{"34":2}}],["非模态分割",{"0":{"34":1}}],["svg",{"0":{"15":1,"16":1}}],["synthesis",{"2":{"34":1}}],["synthetic",{"2":{"34":1},"4":{"34":1}}],["similarity",{"2":{"34":1}}],["signal",{"2":{"34":1}}],["styles",{"0":{"27":1,"28":1,"29":1,"30":2,"31":1,"32":2},"1":{"30":1,"32":1}}],["structural",{"2":{"34":1}}],["stuff",{"2":{"34":1}}],["studies",{"2":{"34":1}}],["ssim",{"2":{"34":2}}],["square",{"2":{"34":2}}],["scripts",{"0":{"1":1,"18":1,"19":1,"20":1,"21":1,"22":1,"23":1,"24":1,"26":1}}],["score",{"2":{"34":2}}],["scene",{"2":{"34":1}}],["scenes",{"2":{"34":2},"4":{"34":1}}],["supported",{"0":{"31":1},"1":{"31":1}}],["supermarket",{"2":{"34":1}}],["survey",{"0":{"34":1},"1":{"34":1},"2":{"34":1},"4":{"34":1}}],["specialized",{"2":{"34":2},"4":{"34":1}}],["specific",{"2":{"34":3}}],["sail",{"2":{"34":1}}],["segmented",{"2":{"34":1}}],["segmentation",{"2":{"34":5}}],["segan",{"2":{"34":1}}],["shape",{"2":{"34":5},"4":{"34":2}}],["24",{"2":{"34":1}}],["2d5198822ab091ce4305",{"0":{"4":1},"1":{"4":1}}],["2d",{"2":{"34":3},"4":{"34":1}}],["2022a",{"2":{"34":1}}],["2022",{"2":{"34":2}}],["2021",{"2":{"34":8}}],["2018",{"2":{"34":1}}],["2019",{"2":{"34":10}}],["2017",{"2":{"34":4}}],["2016",{"2":{"34":1}}],["2",{"2":{"34":6},"4":{"34":6}}],["human",{"2":{"34":1}}],["hu",{"2":{"34":1}}],["handling",{"2":{"34":1}}],["html",{"0":{"17":2,"34":1}}],["issues",{"2":{"34":1},"4":{"34":1}}],["iou",{"2":{"34":2}}],["iodine",{"2":{"34":1}}],["ibbe",{"2":{"34":1}}],["inception",{"2":{"34":1}}],["index",{"2":{"34":1}}],["intersection",{"2":{"34":1}}],["introduction",{"2":{"34":1},"4":{"34":1}}],["instaorder",{"2":{"34":2}}],["instance",{"2":{"34":3}}],["images",{"2":{"34":1},"4":{"34":1}}],["image",{"0":{"34":1},"1":{"34":1},"2":{"34":3},"4":{"34":2}}],["1data",{"2":{"34":1},"4":{"34":1}}],["1",{"2":{"34":5},"4":{"34":5}}],["ar",{"2":{"34":1}}],["artifacts",{"2":{"34":1}}],["art",{"2":{"34":1},"4":{"34":1}}],["accuracy",{"2":{"34":1}}],["asn",{"2":{"34":1}}],["average",{"2":{"34":2}}],["ahp",{"2":{"34":2}}],["aps",{"2":{"34":2}}],["appearance",{"2":{"34":4},"4":{"34":2}}],["annotations",{"2":{"34":2}}],["annotation",{"2":{"34":1},"4":{"34":1}}],["al",{"2":{"34":21}}],["a",{"1":{"34":1},"2":{"34":2},"4":{"34":1}}],["amodal补全任务与目标检测",{"2":{"34":1}}],["amodal数据集的挑战",{"2":{"34":1}}],["amodalmask",{"2":{"34":1}}],["amodal",{"0":{"34":1},"1":{"34":1},"2":{"34":31},"4":{"34":6}}],["论文的",{"2":{"34":1}}],["论文通过对现有非模态补全数据集的分类与总结",{"2":{"34":1}}],["论文",{"0":{"34":1},"1":{"34":1},"2":{"34":1},"4":{"34":1}}]],"serializationVersion":2}